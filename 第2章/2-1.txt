教師あり学習、および偏りと過適合の概念

教師あり学習は入力を関数fに入れ、それっぽい出力yを出すこと
入力: x, 出力: y, 学習モデル: f
 f (x) = y

入力は学習サンプルを集めることで行う
元のデータ分布(X,Y)
サンプリングしたデータ(x,y)
これはこの世のすべてのデータを得ることができないからだと思われる。
i.i.d. =  "independent and identically distributed" 独立かつ同一の分布
つまり真のデータ分布からサンプリングした(x,y)ということを指す

独立かつ同一分布でないといけない
独立：何かをサンプリングした結果が次のサンプリングに影響しない
同一分布：テストデータと訓練データでデータが同じ確率分布に従っていること

このデータ(x,y)の集合Dlsは学習するデータセットと言える
X内のxについてのモデルの予測値はf(x|Dls)と言える
ただし、xはDlsに入ってないことを想定していると思われる

Dls ~ 斜体(Dls)はDlsの分布をもとに斜体(Dls)が作成される
斜体(Dls)はDlsによって定義される経験分布を指す
みなさん経験分布ってわかる？

f(x|Dls)が確率変数であり、入力空間上におけるxの平均誤差とは....?
ここは意味不明
確率変数：xが未知だったりするから
平均誤差：Dlsで無作為サンプリングしてるから？
たくさんのxのブレ→モデルの予測の誤差に繋がるため、平均誤差？

この量（平均誤差を指すと思う）の期待値は以下の式になる
I[f] = E[X]E[Dls]E[Y|X] L(Y,f(X|Dls))
E[X] : 真のデータ分布の期待値
E[Dls] : サンプリングしたデータの期待値
E[Y|X] : 入力Xが与えられる前提の出力Yの期待値
　　　　　入力と出力が1対1対応ではないのかも、確率分布だからかな？
L(Y,f(X|Dls)) : 予測値と真の値の差→損失

Lを平均二乗誤差と仮定すると、誤差は偏り項と分散項に分解できるらしい？
偏り: モデルの選択・アルゴリズムの誤った仮定
　このデータはこの分布に沿っているに違いないなどの予想？
　あとは使う活性化関数や、分類器の設定ミス？
分散項（過適合誤差） : 有限のデータ分布で学習することによる誤差
　真の分布が見れないことによる予測したデータ分布と真の分布の差

結合確率分布 : 複数の確率変数が同時に特定の値をとり、それぞれの組み合わせに確率を対応させた確率分布のこと
　パラメータがたくさんある確率分布ということ
I[f]はパラメータを期待値の3つと損失の計4つ持っている（損失の中も数えると増える）
そのため、結合確率分布が必要になってくる

これの対策として、経験誤差Isを用いる
Is = ΣL(yi,f(xi))/n
汎化誤差 : G = I[f] - Is[f]
Gはサンプルしたデータと未知の結合確率分布の差である

機械学習したモデルは、どの分類器を使うかで汎化誤差の上限が決まる
これはラーマン複雑度（？）やVC次元（？）という尺度を使うとわかる
深層学習モデルは表現力が高く、どのような関数でも表現できるとされている

